# Database connection
DATABASE_URL=postgresql+asyncpg://postgres:postgres@localhost:5432/ragdb

# Storage directory for uploaded documents
STORAGE_DIR=./storage

# Maximum upload size in bytes (default: 100MB)
MAX_UPLOAD_SIZE=104857600

# Embedding model
# You can use either a Hugging Face model id OR a local folder path.
# If your server cannot access huggingface.co, download the model to ./models and set a local path, e.g.:
# EMBEDDING_MODEL=./models/bge-small-zh-v1.5
EMBEDDING_MODEL=BAAI/bge-small-zh-v1.5

# Hugging Face / Transformers networking (optional)
# Use a mirror endpoint if huggingface.co is unreachable from your server.
# HF_ENDPOINT=https://hf-mirror.com
# Cache locations (optional)
# HF_HOME=./.cache/huggingface
# TRANSFORMERS_CACHE=./.cache/huggingface
# SENTENCE_TRANSFORMERS_HOME=./.cache/sentence-transformers
# Offline mode (only after you've downloaded all needed models)
# HF_HUB_OFFLINE=1
# TRANSFORMERS_OFFLINE=1

# LLM model path (download the model and place it in this directory)
LLM_MODEL_PATH=./models/Qwen2.5-0.5B-Instruct

# Processing concurrency
INDEXING_CONCURRENCY=1
GENERATION_CONCURRENCY=1

# Chunking parameters
CHUNK_SIZE=500
CHUNK_OVERLAP=50

# Retrieval parameters
DEFAULT_TOP_K=5

# LLM generation parameters
LLM_MAX_INPUT_LENGTH=2000
LLM_MAX_NEW_TOKENS=512
LLM_TEMPERATURE=0.7
LLM_TOP_P=0.9

# External OCR service URL (optional, leave empty if not used)
# Expected API contract:
# POST /ocr with multipart/form-data file upload
# Response: {"pages": [{"page": 1, "text": "..."}]}
#
# Quick start with the bundled OCR container:
#   docker compose up -d ocr
# Then set:
#   OCR_SERVICE_URL=http://127.0.0.1:9001/ocr
OCR_SERVICE_URL=http://127.0.0.1:9001/ocr
APT_MIRROR_URL=http://mirrors.aliyun.com/debian
APT_SECURITY_URL=http://mirrors.aliyun.com/debian-security
